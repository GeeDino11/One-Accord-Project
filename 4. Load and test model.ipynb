{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f08e147-516d-44f8-b9c9-419799109596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GeeDino/bert-base-tweet-topic-classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"GeeDino/bert-base-tweet-topic-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe43ac9-8aff-4da8-87b6-dd304f4d56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, BertForSequenceClassification, BertTokenizerFast\n",
    "\n",
    "nlp= pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e75410e-8bca-4982-a3ae-893a8f65a90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Other', 'score': 0.9966984391212463}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"Machine Learning and automation is awesome!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c259fb24-bcc8-429d-9638-4f0724056cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def predict(text):\n",
    "#     \"\"\"\n",
    "#     Predicts the class label for a given input text.\n",
    "\n",
    "#     Args:\n",
    "#         text (str): The input text for which the class label needs to be predicted.\n",
    "#         model: The BERT model for classification.\n",
    "#         tokenizer: The tokenizer corresponding to the BERT model.\n",
    "\n",
    "#     Returns:\n",
    "#         pred_label (str): The predicted class label.\n",
    "#     \"\"\"\n",
    "#     # Tokenize the input text\n",
    "#     inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "#     # Move tensors to the CPU\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "\n",
    "#     # Move the model to the CPU\n",
    "#     model.to(device)\n",
    "\n",
    "#     # Get model output (logits)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#     probs = outputs.logits.softmax(1)\n",
    "\n",
    "#     # Get the index of the class with the highest probability\n",
    "#     pred_label_idx = probs.argmax()\n",
    "\n",
    "#     # Map the predicted class index to the actual class label\n",
    "#     pred_label = model.config.id2label[pred_label_idx.item()]\n",
    "\n",
    "#     return pred_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c85aed-5085-4963-abb3-035e41cbfb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test model\n",
    "# text = \"Machine Learning and automation is awesome!!\"\n",
    "\n",
    "# predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99361a8a-223a-4d5c-a048-c90bce710bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def predict(text):\n",
    "#     \"\"\"\n",
    "#     Predicts the class label for a given input text.\n",
    "\n",
    "#     Args:\n",
    "#         text (str): The input text for which the class label needs to be predicted.\n",
    "#         model: The BERT model for classification.\n",
    "#         tokenizer: The tokenizer corresponding to the BERT model.\n",
    "\n",
    "#     Returns:\n",
    "#         probs (torch.Tensor): Class probabilities for the input text.\n",
    "#         pred_label_idx (torch.Tensor): The index of the predicted class label.\n",
    "#         pred_label (str): The predicted class label.\n",
    "#     \"\"\"\n",
    "#     # Tokenize the input text\n",
    "#     inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "#     # Move tensors to the CPU\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "\n",
    "#     # Move the model to the CPU\n",
    "#     model.to(device)\n",
    "\n",
    "#     # Get model output (logits)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#     probs = outputs.logits.softmax(dim=1)\n",
    "\n",
    "#     # Get the index of the class with the highest probability\n",
    "#     pred_label_idx = probs.argmax(dim=1)\n",
    "\n",
    "#     # Map the predicted class index to the actual class label\n",
    "#     pred_label = model.config.id2label[pred_label_idx.item()]\n",
    "\n",
    "#     return probs, pred_label_idx, pred_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cec97d-5d5e-4ea2-95ad-20dd00f1789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test model\n",
    "# text = \"Machine Learning and automation is awesome!!\"\n",
    "\n",
    "# predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1fd70-cc01-4d9d-9d2a-92b157b3d318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
